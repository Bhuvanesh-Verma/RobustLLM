program: hpt.py
method: bayes
metric:
  name: macro_f1
  goal: maximize
parameters:
  learner_lr:
    min: 0.000005
    max: 0.0005
  aux_lr:
    min: 0.0005
    max: 0.01
  epoch:
    min: 1
    max: 5
  aux_hidden_size1:
    values: [256, 512, 1024]
  aux_hidden_size2:
    values: [0, 32, 64, 128]
  aux_hidden_size3:
    values: [0, 16, 32, 64]
  patience:
    values: [1, 2, 3, 4]
  base_model:
    values: ["models/Mistral-7B-v0.1", "models/Mistral-7B-Instruct-v0.2"]