program: hpt.py
method: bayes
metric:
  name: val_avg_loss
  goal: minimize
parameters:
  max_length:
    values: [ 1024, 2048 ]
  lora_r:
    values: [ 8,16,32,64 ]
  lora_alpha:
    values: [ 16,32,64,128 ]
  lora_dropout:
    values: [ 0.05, 0.1, 0.2 ]
  learner_lr:
    min: 0.000005
    max: 0.005
  aux_lr:
    min: 0.0005
    max: 0.01
  epoch:
    min: 1
    max: 5
  aux_hidden_size:
    values: [ 64, 128, 256, 512, 1024 ]
  patience:
    values: [ 3, 5, 7, 10 ]
  base_model:
    values: [ "models/Mistral-7B-v0.1", "models/Mistral-7B-Instruct-v0.2" ]
  prompt_type:
    values: [ "train", "train_base" ]